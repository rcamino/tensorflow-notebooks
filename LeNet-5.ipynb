{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = mnist.train.images.shape[1]\n",
    "image_height = int(np.sqrt(image_size))\n",
    "image_width = int(np.sqrt(image_size))\n",
    "print(\"{:d} = {:d} x {:d}\".format(image_size, image_height, image_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_size = mnist.train.labels.shape[1]\n",
    "print(labels_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(name, shape):\n",
    "    return tf.get_variable(name, shape, dtype=np.float32,\n",
    "        initializer=tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode=\"FAN_IN\", uniform=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(name, shape):\n",
    "    return tf.get_variable(name, shape, dtype=np.float32, initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(name, t_input, patch, input_channels, output_channels):\n",
    "    with tf.variable_scope(name):\n",
    "        t_weight = weight_variable(\"weight\", [patch, patch, input_channels, output_channels])\n",
    "        t_conv = tf.nn.conv2d(t_input, t_weight, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv\")\n",
    "        t_bias = bias_variable(\"bias\", [output_channels])\n",
    "        t_linear = tf.add(t_conv, t_bias, name=\"linear\")\n",
    "        t_activation = tf.nn.tanh(t_linear, name=\"activation\")\n",
    "    return t_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(name, x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\", name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(name, t_input, input_size, hidden_size, activation=True):\n",
    "    with tf.variable_scope(name):\n",
    "        t_weight = weight_variable(\"weight\", [input_size, hidden_size])\n",
    "        t_matmul = tf.matmul(t_input, t_weight, name=\"matmul\")\n",
    "        t_bias = bias_variable(\"bias\", [hidden_size])\n",
    "        t_linear = tf.add(t_matmul, t_bias, name=\"linear\")\n",
    "        if activation:\n",
    "            return tf.nn.tanh(t_linear, name=\"activation\")\n",
    "        else:\n",
    "            return t_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_channels = 1\n",
    "conv1_channels = 6\n",
    "conv1_patch = 5\n",
    "conv2_channels = 16\n",
    "conv2_patch = 5\n",
    "fc_input = conv2_channels * conv2_patch * conv2_patch\n",
    "fc1_hidden = 120\n",
    "fc2_hidden = 84\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "t_flat_images = tf.placeholder(tf.float32, shape=[None, image_size], name=\"flat_images\")\n",
    "t_labels = tf.placeholder(tf.float32, shape=[None, labels_size], name=\"labels\")\n",
    "\n",
    "t_square_images = tf.reshape(t_flat_images, [-1, image_height, image_width, image_channels], name=\"square_images\")\n",
    "t_padded_images = tf.pad(t_square_images, [[0, 0], [2, 2], [2, 2], [0, 0]], name=\"padded_images\")\n",
    "\n",
    "t_conv1 = conv2d(\"conv1\", t_padded_images, conv1_patch, image_channels, conv1_channels)\n",
    "\n",
    "t_sampling1 = max_pool_2x2(\"sampling1\", t_conv1)\n",
    "\n",
    "t_conv2 = conv2d(\"conv2\", t_sampling1, conv2_patch, conv1_channels, conv2_channels)\n",
    "\n",
    "t_sampling2 = max_pool_2x2(\"sampling2\", t_conv2)\n",
    "\n",
    "t_fc_input = tf.reshape(t_sampling2, [-1, fc_input], name=\"fc_input\")\n",
    "\n",
    "t_fc1 = fc(\"fc1\", t_fc_input, fc_input, fc1_hidden)\n",
    "\n",
    "t_fc2 = fc(\"fc2\", t_fc1, fc1_hidden, fc2_hidden)\n",
    "\n",
    "t_logits = fc(\"fc3\", t_fc2, fc2_hidden, labels_size, activation=False)\n",
    "t_predictions = tf.nn.softmax(t_logits, name=\"predictions\")\n",
    "\n",
    "t_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=t_logits, labels=t_labels))\n",
    "t_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(t_loss)\n",
    "\n",
    "t_correct = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "        tf.equal(tf.argmax(t_predictions, 1), tf.argmax(t_labels, 1)),\n",
    "        tf.float32\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "log_every_batches = 100\n",
    "\n",
    "def run_batches(batches, train=True):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct = 0.0\n",
    "    \n",
    "    iterations = batches.num_examples // batch_size\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        batch = batches.next_batch(batch_size)\n",
    "\n",
    "        if train:\n",
    "            sess.run(t_optimizer, feed_dict={t_flat_images: batch[0], t_labels: batch[1]})\n",
    "            \n",
    "        loss, correct = sess.run([t_loss, t_correct],\n",
    "                                 feed_dict={t_flat_images: batch[0], t_labels: batch[1]})\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        epoch_correct += correct\n",
    "        \n",
    "        if train and iteration % log_every_batches == log_every_batches - 1:\n",
    "            print(\"Train Batch: {:5d} Loss: {:.4f}\".format(iteration + 1, loss))\n",
    "\n",
    "    return epoch_loss / iterations, epoch_correct / (iterations * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch_id in range(epochs):\n",
    "        train_loss, train_accuracy = run_batches(mnist.train, train=True)\n",
    "        test_loss, test_accuracy = run_batches(mnist.test, train=False)\n",
    "\n",
    "        print(\"Epoch: {:5d} Train Loss: {:.4f} Test Loss: {:.4f} Train Accuracy: {:.4f} Test Accuracy: {:.4f}\".format(\n",
    "            epoch_id + 1, train_loss, test_loss, train_accuracy, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
